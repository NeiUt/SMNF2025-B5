@inproceedings{jahanbakhsh2023,
author = {Jahanbakhsh, Farnaz and Katsis, Yannis and Wang, Dakuo and Popa, Lucian and Muller, Michael},
title = {Exploring the Use of Personalized AI for Identifying Misinformation on Social Media},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581219},
doi = {10.1145/3544548.3581219},
abstract = {This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user’s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users’ judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {27},
keywords = {Artificial Intelligence, Democratized Content Moderation, Fact Checking, Misinformation, Social Media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@article{Quelle2,
title = {Requirements engineering for artificial intelligence systems: A systematic mapping study},
journal = {Information and Software Technology},
volume = {158},
pages = {107176},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107176},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923000307},
author = {Khlood Ahmad and Mohamed Abdelrazek and Chetan Arora and Muneera Bano and John Grundy},
keywords = {Requirements engineering, Software engineering, Artificial intelligence, Machine learning, Systematic mapping study},
abstract = {Context:
In traditional software systems, Requirements Engineering (RE) activities are well-established and researched. However, building Artificial Intelligence (AI) based software with limited or no insight into the system’s inner workings poses significant new challenges to RE. Existing literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI).
Objective:
This paper investigates current approaches for specifying requirements for AI systems, identifies available frameworks, methodologies, tools, and techniques used to model requirements, and finds existing challenges and limitations.
Method:
We performed a systematic mapping study to find papers on current RE4AI approaches. We identified 43 primary studies and analyzed the existing methodologies, models, tools, and techniques used to specify and model requirements in real-world scenarios.
Results:
We found several challenges and limitations of existing RE4AI practices. The findings highlighted that current RE applications were not adequately adaptable for building AI systems and emphasized the need to provide new techniques and tools to support RE4AI.
Conclusion:
Our results showed that most of the empirical studies on RE4AI focused on autonomous, self-driving vehicles and managing data requirements, and areas such as ethics, trust, and explainability need further research.}
}
@article{LekshmiAmmal2025,
  author = {Lekshmi Ammal, Hariharan Ramakrishna Iyer and Madasamy, Anand Kumar},
  title = {A reasoning based explainable multimodal fake news detection for low resource language using large language models and transformers},
  journal = {Journal of Big Data},
  volume = {12},
  number = {1},
  pages = {46},
  year = {2025},
  month = {02},
  day = {23},
  abstract = {Nowadays, individuals rely predominantly on online social media platforms, news feeds, websites, and news aggregator applications to acquire recent news stories. This trend has resulted in an increase in the number of available social media platforms, online news feeds, and news aggregator applications. These news platforms have been accused of spreading fake news to gain more attention and recognition. Earlier, this misinformation or fake news used to be propagated only in the text form. However, with the advent of technology, now it is spread in multimodal forms, such as images with text, videos, and audio with textual content. Currently, the automatic fake news detection models are focused on high resource languages and superficial output. Social media users need clarity and reasoning when it comes to identifying fake news, rather than just a superficial classification of news as fake. Providing context, reasoning, and explanations can help users understand why certain news is misleading or false. Hence, a multimodal system has to be developed to identify and justify fake news. In this proposed work, we have developed a multimodal fake news system for the Low Resource Language Tamil with reasoning-based explainability. The dataset for this proposed work is retrieved from fact-check websites and official news websites. We have experimented with different combinations of models for visual and text modalities. Further, we integrated LLM-based image descriptions into our model with the text and visual features, resulting in an F1 score of 0.8736. We used the Siamese model to determine the similarity of the news and its image descriptions. Additionally, we conducted error analysis and used explainable artificial intelligence to explore the reasoning behind our model's predictions. We also present the textual reasoning for the model's predictions and match them with images.},
  issn = {2196-1115},
  doi = {10.1186/s40537-025-01093-x},
  url = {https://doi.org/10.1186/s40537-025-01093-x}
}


