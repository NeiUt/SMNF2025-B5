---
title: "SMNF2025-B5"
author:
- Mattis Becker
- Justus H
- Tommy P
- Aliaksandra F
- Paul Riehle
- Jakob L

format: 
  html: 
    toc: true
  pdf:
    toc: true
    papersize: a4
    geometry: margin=2.5cm
    documentclass: article
    fontsize: 12pt
    number-sections: true
editor: visual
date: today
bibliography: Literatur.bib
---

##Link des Repositories

https://github.com/NeiUt/SMNF2025-B5/tree/main

##Aktueller Hash:

```{r}
#| label: Commit Hash
#| echo: false
commit_hash <- system("git rev-parse --short=7 HEAD", intern = TRUE)
commit_hash

```

# Code of Conduct

-   Umgang mit Feedback, unterschiedlichen Perspektiven und Meinungsverschiedenheiten:

    -   Feedback wird ehrlich aufgenommen und bei zukünftigen Arbeiten angewendet

-   Faire Aufteilung der Arbeitslast:

    -   Die zu erledigenden Aufgaben werden gerecht und in Absprache aufgeteilt.

-   Verhalten in Bezug auf vereinbarte und verpflichtende Termine:

    -   Termine für gemeinsames projektorientiertes Arbeiten, werden per Online-Messanger vereinbart und die Gruppenmitglieder finden sich dann in einem Videoanruf ein oder es wird sich in Präsenz getroffen.

-   Einhaltung der wissenschaftlichen Integrität:

    -   Es werden nur verlässliche Quellen verwendet, die auch korrekt zitiert werden und geschriebenes wird objektiv verfasst.

-   Verpflichtung zum Schutz von Daten und zur Wahrung ihrer Vertraulichkeit:

    -   Daten werden vertaulich behandelt und nicht an Dritte weitergegeben.

-   Nutzung und Kennzeichnung von AI Tools (z.B. ChatGPT):

    -   Nutzung von AI tools wird gekennzeichnet und nicht direkt übernommen.

# Einleitung

*(Einleitung eingefügen)*

# Literaturübersicht

Fake News verbreiten sich oft durch manipulierte Bilder, Deepfakes und bearbeiteten Ton. Diese Inhalte können schnell die öffentliche Meinung beeinflussen, Vertrauen zerstören und Verschwörungstheorien verstärken. Deshalb ist Medienkompetenz sehr wichtig.

Ein automatisiertes System wurde entwickelt, um Fake News in Tamil zu erkennen. Dafür wurde ein Datensatz mit Überschriften, Texten und Bildern erstellt. Die Nachrichten wurden in „true“, „false“ und „fake“ eingeteilt.

Zur Verarbeitung kamen Transformer-Modelle für Text und Bild zum Einsatz. Ein siamesisches Modell prüfte, ob Text und Bild zusammenpassen. LLMs erstellten automatisch Bildbeschreibungen zur besseren Analyse.

Das System erreichte eine gute Erkennungsrate (F1-Score: 0,8736). Mit erklärbarer KI wurden die Entscheidungen des Modells verständlich gemacht. [@LekshmiAmmal2025]

Die Arbeit “Requirements engineering for artificial intelligence systems: A systematic mapping study” befasst sich insbesondere mit der Fragestellung, wie Anforderungsstellung an moderne KI-Systeme erfplgt und welche verfügbaren Frameworks, Methoden, Werkzeuge und Techniken dazu verwendet werden und welche Limitierungen und Herausforderungen der Anforderungsstellung sich dabei vorfinden lassen.

Basierend auf 43 referenzierten Studien wurden die darin verwendeten Methoden, Modelle, Werkzeuge und Techniken der Anforderungsstellung analysiert.

Basierend auf der Analyse wird in der Arbeit ersichtlich, dass betrachtete KI-Systeme mangelnde Intergration aktueller Anforderungsmodelle, Werkzeuge und Methoden aufweisen. Nach der Analyse der 43 Studien ergab sich, dass es noch viele Herausforderungen in der Anforderungsstellung an KI-Systeme gibt, wobei besondere Schwerpunkte die Erklärbarkeit generierter Inhalte, ethische Fragen, Fragen der Datenanforderungen und Mangel an Kommunikation zwischen Softwareentwicklern und Data Scientists. [@Quelle2]

Die Arbeit der Autoren Farnaz Jahanbakhsh, Yannis Katsis, Dakuo Wang, Lucian Popa und Michael Müller hat sich mit der Fragestellung beschäftigt, wie menschliche Bewertungen und KI-Vorhersagen zusammen genutzt werden können, um Fehlinformationen in Online-Beiträgen zu erkennen. Dabei geht es darum, die Zusammenarbeit zwischen Nutzern und einer personalisierten künstlichen Intelligenz (KI) zu untersuchen, um die Genauigkeit bei der Bewertung von Beiträgen, besonders auf sozialen Medien, zu verbessern und mögliche Probleme zu Analysieren. Das Ziel ist herauszufinden, ob eine solche personalisierte KI, Menschen dabei helfen kann, die Vertrauenswürdigkeit von Online-Inhalten besser einzuschätzen. Es wurde untersucht, wie Nutzer mit der vorhersage der KI interagieren, ob sie davon profitieren und oder ob Probleme auftreten könnten. Ein Vorteil der personalisierten KI ist, dass sie Nutzer als helfer dienen kann. Sie kann dem Nutzer helfen potentielle Falschinformationen zu erkennen, bevor diese weitergeleitet werden. Jedoch gibt auch Herausforderungen, denn die KI könnte fehlerhafte Vorhersagen machen, die die Bewertung des Nutzers beeinflussen. So könnten falsche Informationen als glaubwürdig erkannt werden. Des Weiteren gibt es die Befürchtung, dass der Einsatz so einer KI, insbesondere durch Plattformbetreiber, die Meinungsfreiheit einschränken könnte. Das wird zum einen von Wissenschaftlern als auch zum anderen von Nutzern kritisch gesehen. Die KI analysiert, wie ein Nutzer in der Vergangenheit Inhalte eingeschätzt hat, und erstellt daraus eine Person bezogene vorhersage. Dieses Modell sagt dann voraus, wie der jeweilige Nutzer wahrscheinlich aktuelle Inhalte bewerten würde. Etwa ob ein Tweet wahr oder eine Fehlinformation ist. Die Nutzerstudie zeigt, dass eine personalisierte KI die Nutzer durch ihre Vorhersagen Beeinflusst. Dieser Effekt verschwand jedoch, wenn die Nutzer der Bewertung nachgingen durch eine Begründung ihrer Entscheidung

[@jahanbakhsh2023]

# Methode

\*Wir haben uns für einen qualitativ-explorativen Ansatz entschieden, da dieser ermöglicht, subjektive Erfahrungen, Bedarfe und Erwartungen von Social-Media-Nutzer hinsichtlich einer KI-basierten Misinformations­erkennung offen zu erfassen. Für unsere Untersuchung führten wir zwei Interviews mit Studierenden durch, die regelmäßig soziale Medien nutzen. Das erste Interview fand am 25.05.2025 statt, der Teilnehmende wird hier als "B5_01" bezeichnet , der zweite Teilnehmende "B5_02" am 26.05.2025. Beide Interviews dauerten jeweils 10-15 Minuten und wurden Digital aufgezeichnet.

Zunächst nutzten wir "Whisper" für die automatische Transkription, anschließend bearbeiteten wir die Texte manuell nach. Dabei ergänzten wir Zeilennummern, ersetzten Namen durch Pseudonyme und markierten Sprecherwechsel durch Kürzel (I für Interviewende, B5 für Teilnehmende). Identifizierende Details wurden vollständig anonymisiert.

Für die Datenauswertung nutzten wir die thematische Analyse nach Braun & Clarke, die ein strukturiertes Vorgehen zum Erkennen von Mustern in qualitativen Daten ermöglicht. Wir codierten gemeinsam in MaxQDA, besprachen unsere Codes und fassten zusammengehörige Codes zu drei übergeordneten Themen zusammen, um die Analyse übersichtlich und nachvollziehbar zu gestalten.\*

# Ergebnisse

*(Ergebnisse einfügen)*

Analyse:

|  |  |  |  |
|----------------------------------------------|------------------------------------------------------------------------------------|--|-----------------------------------------------------------------------------------------------------------------------------------|
| Name | Vorwissen | Implementierung | Gefahren
von KI-Tools |
| Definition | Erfahrungen
mit social media, fake news und KI-Tools. | KI-Tools
sollten benutzt werden um den Grad der Falschinformationen zu Kennzeichnen.
Außerdem leicht erreichbar sein, aber nicht prägnant im Vordergrund stehen. | Ethische
Fragenstellung wer diese KI-Tools kontrolliert und welchen Einfluss hat eine
fehlende Kennzeichnung. |
| Textstelle | „Also, mir ist das erst quasi zur Corona-Zeit richtig aufgefallen. Da wurde ja sehr, sehr viel Fehlinformation und Halbwahrheiten gestreut. Da habe ich auch entdeckt, dass das teilweise gekennzeichnet worden ist, dass das nicht komplett der Wahrheit entspricht. Sowohl als YouTube als auch Instagram, ich glaube auf TikTok sogar auch.“ (B5_01, Zeile 68-73) | „Ich denke, es sollte schon immer präsent sein, damit sich auch Falschnachrichten generell einfach weniger verbreiten. Gleichzeitig sollte es aber natürlich nicht zu präsent sein und nicht zu viel Platz in der Anwendung einnehmen. “ (B5_02, Zeile 113-116). „Vor allem in Situationen, wo man meinen könnte, dass die Information wirklich zutreffend ist, weil das für das eigene Bild in einem gewissen Themenbereich sehr wahrscheinlich klingt oder einleuchtend klingt, dass man das dann tendenziell sogar eher aufnehmen kann. KI's könnten da wirklich helfen, Nutzer aufmerksam zu machen, dass sich das da nicht um eine verifizierte Meinung handelt, sondern um irgendwelche erfundenen Sachen oder gezielten Fehlinformationen.“ (B5_01, Zeile 97-105) | „Ja also ich finde das sollte ein gesondertes team sein es gibt ja auch zum beispiel ein ethik rat wenn es um thema ki geht was ki machen darf und was nicht. Die wären zum Beispiel eine interessante Anlaufstelle dafür, damit man halt so gut es geht Einflüsse von Dritten vermeiden könnte, die halt interne Ziele verfolgen.“ (B5_01, Zeile 197-202) „Andererseits würde ich auch eine kleine Gefahr darin sehen, wenn man als Mensch diese KI dafür nutzt, um sich Informationen bestätigen zu lassen oder den Wahrheitsgehalt herauszufinden. Wenn man sich dann fälschlicherweise zu sehr auf die KI verlässt und die KI aber doch mal einen Fehler macht, wie das aktuell auch schon vorkommt.“ (B5_02, Zeile 82-87) |

# Diskussion

## *(Diskussion einfügen)*

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

"Tommy05lol"

"DefoNotAlex"

"Matt1s1234"

"NeiUt"
