---
title: "SMNF2025-B5"
author:
- Mattis Becker
- Justus H
- Tommy P
- Aliaksandra F
- Paul Riehle
- Jakob L

format: 
  html:
    number-sections: true
    toc: true
  pdf:
    toc: true
    papersize: a4
    geometry: margin=2.5cm
    documentclass: article
    fontsize: 12pt
    number-sections: true
citation-location: document
editor: visual
date: today
bibliography: Literatur.bib
---

##Link des Repositories

https://github.com/NeiUt/SMNF2025-B5/tree/main

##Aktueller Hash:

```{r}
#| label: Commit Hash
#| echo: false
commit_hash <- system("git rev-parse --short=7 HEAD", intern = TRUE)
commit_hash

```

# Code of Conduct

-   Umgang mit Feedback, unterschiedlichen Perspektiven und Meinungsverschiedenheiten:

    -   Feedback wird ehrlich aufgenommen und bei zukÃ¼nftigen Arbeiten angewendet

-   Faire Aufteilung der Arbeitslast:

    -   Die zu erledigenden Aufgaben werden gerecht und in Absprache aufgeteilt.

-   Verhalten in Bezug auf vereinbarte und verpflichtende Termine:

    -   Termine fÃ¼r gemeinsames projektorientiertes Arbeiten, werden per Online-Messanger vereinbart und die Gruppenmitglieder finden sich dann in einem Videoanruf ein oder es wird sich in PrÃ¤senz getroffen.

-   Einhaltung der wissenschaftlichen IntegritÃ¤t:

    -   Es werden nur verlÃ¤ssliche Quellen verwendet, die auch korrekt zitiert werden und geschriebenes wird objektiv verfasst.

-   Verpflichtung zum Schutz von Daten und zur Wahrung ihrer Vertraulichkeit:

    -   Daten werden vertaulich behandelt und nicht an Dritte weitergegeben.

-   Nutzung und Kennzeichnung von AI Tools (z.B. ChatGPT):

    -   Nutzung von AI tools wird gekennzeichnet und nicht direkt Ã¼bernommen.

# Einleitung

*(Einleitung eingefÃ¼gen)*

# LiteraturÃ¼bersicht

Fake News verbreiten sich oft durch manipulierte Bilder, Deepfakes und bearbeiteten Ton. Diese Inhalte kÃ¶nnen schnell die Ã¶ffentliche Meinung beeinflussen, Vertrauen zerstÃ¶ren und VerschwÃ¶rungstheorien verstÃ¤rken. Deshalb ist Medienkompetenz sehr wichtig.

Ein automatisiertes System wurde entwickelt, um Fake News in Tamil zu erkennen. DafÃ¼r wurde ein Datensatz mit Ãœberschriften, Texten und Bildern erstellt. Die Nachrichten wurden in â€trueâ€œ, â€falseâ€œ und â€fakeâ€œ eingeteilt.

Zur Verarbeitung kamen Transformer-Modelle fÃ¼r Text und Bild zum Einsatz. Ein siamesisches Modell prÃ¼fte, ob Text und Bild zusammenpassen. LLMs erstellten automatisch Bildbeschreibungen zur besseren Analyse.

Das System erreichte eine gute Erkennungsrate (F1-Score: 0,8736). Mit erklÃ¤rbarer KI wurden die Entscheidungen des Modells verstÃ¤ndlich gemacht. [@LekshmiAmmal2025]

Die Arbeit â€œRequirements engineering for artificial intelligence systems: A systematic mapping studyâ€ befasst sich insbesondere mit der Fragestellung, wie Anforderungsstellung an moderne KI-Systeme erfplgt und welche verfÃ¼gbaren Frameworks, Methoden, Werkzeuge und Techniken dazu verwendet werden und welche Limitierungen und Herausforderungen der Anforderungsstellung sich dabei vorfinden lassen.

Basierend auf 43 referenzierten Studien wurden die darin verwendeten Methoden, Modelle, Werkzeuge und Techniken der Anforderungsstellung analysiert.

Basierend auf der Analyse wird in der Arbeit ersichtlich, dass betrachtete KI-Systeme mangelnde Intergration aktueller Anforderungsmodelle, Werkzeuge und Methoden aufweisen. Nach der Analyse der 43 Studien ergab sich, dass es noch viele Herausforderungen in der Anforderungsstellung an KI-Systeme gibt, wobei besondere Schwerpunkte die ErklÃ¤rbarkeit generierter Inhalte, ethische Fragen, Fragen der Datenanforderungen und Mangel an Kommunikation zwischen Softwareentwicklern und Data Scientists. [@Quelle2]

Die Arbeit der Autoren Farnaz Jahanbakhsh, Yannis Katsis, Dakuo Wang, Lucian Popa und Michael MÃ¼ller hat sich mit der Fragestellung beschÃ¤ftigt, wie menschliche Bewertungen und KI-Vorhersagen zusammen genutzt werden kÃ¶nnen, um Fehlinformationen in Online-BeitrÃ¤gen zu erkennen. Dabei geht es darum, die Zusammenarbeit zwischen Nutzern und einer personalisierten kÃ¼nstlichen Intelligenz (KI) zu untersuchen, um die Genauigkeit bei der Bewertung von BeitrÃ¤gen, besonders auf sozialen Medien, zu verbessern und mÃ¶gliche Probleme zu Analysieren. Das Ziel ist herauszufinden, ob eine solche personalisierte KI, Menschen dabei helfen kann, die VertrauenswÃ¼rdigkeit von Online-Inhalten besser einzuschÃ¤tzen. Es wurde untersucht, wie Nutzer mit der vorhersage der KI interagieren, ob sie davon profitieren und oder ob Probleme auftreten kÃ¶nnten. Ein Vorteil der personalisierten KI ist, dass sie Nutzer als helfer dienen kann. Sie kann dem Nutzer helfen potentielle Falschinformationen zu erkennen, bevor diese weitergeleitet werden. Jedoch gibt auch Herausforderungen, denn die KI kÃ¶nnte fehlerhafte Vorhersagen machen, die die Bewertung des Nutzers beeinflussen. So kÃ¶nnten falsche Informationen als glaubwÃ¼rdig erkannt werden. Des Weiteren gibt es die BefÃ¼rchtung, dass der Einsatz so einer KI, insbesondere durch Plattformbetreiber, die Meinungsfreiheit einschrÃ¤nken kÃ¶nnte. Das wird zum einen von Wissenschaftlern als auch zum anderen von Nutzern kritisch gesehen. Die KI analysiert, wie ein Nutzer in der Vergangenheit Inhalte eingeschÃ¤tzt hat, und erstellt daraus eine Person bezogene vorhersage. Dieses Modell sagt dann voraus, wie der jeweilige Nutzer wahrscheinlich aktuelle Inhalte bewerten wÃ¼rde. Etwa ob ein Tweet wahr oder eine Fehlinformation ist. Die Nutzerstudie zeigt, dass eine personalisierte KI die Nutzer durch ihre Vorhersagen Beeinflusst. Dieser Effekt verschwand jedoch, wenn die Nutzer der Bewertung nachgingen durch eine BegrÃ¼ndung ihrer Entscheidung

[@jahanbakhsh2023]

# Methode

## Qualitativer Methodenteil

\*Wir haben uns fÃ¼r einen qualitativ-explorativen Ansatz entschieden, da dieser ermÃ¶glicht, subjektive Erfahrungen, Bedarfe und Erwartungen von Social-Media-Nutzer hinsichtlich einer KI-basierten MisinformationsÂ­erkennung offen zu erfassen. FÃ¼r unsere Untersuchung fÃ¼hrten wir zwei Interviews mit Studierenden durch, die regelmÃ¤ÃŸig soziale Medien nutzen. Das erste Interview fand am 25.05.2025 statt, der Teilnehmende wird hier als "B5_01" bezeichnet , der zweite Teilnehmende "B5_02"Â am 26.05.2025. Beide Interviews dauerten jeweils 10-15 Minuten und wurden Digital aufgezeichnet. \>\>\>\>\>\>\> parent of 09c2f40 (Commit 09.06.2025)

ZunÃ¤chst nutzten wir "Whisper" fÃ¼r die automatische Transkription, anschlieÃŸend bearbeiteten wir die Texte manuell nach. Dabei ergÃ¤nzten wir Zeilennummern, ersetzten Namen durch Pseudonyme und markierten Sprecherwechsel durch KÃ¼rzel (I fÃ¼r Interviewende, B5 fÃ¼r Teilnehmende). Identifizierende Details wurden vollstÃ¤ndig anonymisiert.

FÃ¼r die Datenauswertung nutzten wir die thematische Analyse nach Braun & Clarke, die ein strukturiertes Vorgehen zum Erkennen von Mustern in qualitativen Daten ermÃ¶glicht. Wir codierten gemeinsam in MaxQDA, besprachen unsere Codes und fassten zusammengehÃ¶rige Codes zu drei Ã¼bergeordneten Themen zusammen, um die Analyse Ã¼bersichtlich und nachvollziehbar zu gestalten.\*

### Ergebnisse

### Analyse

| Aspekt | Vorwissen | Implementierung | Gefahren |
|------------------|------------------|------------------|------------------|
| **Definition** | Erfahrungen mit Social Media, Fake News und KI-Tools. | KI-Tools sollten benutzt werden, um den Grad der Falschinformationen zu kennzeichnen. AuÃŸerdem leicht erreichbar sein, aber nicht prÃ¤gnant im Vordergrund stehen. | Ethische Fragestellung, wer diese KI-Tools kontrolliert, und welchen Einfluss eine fehlende Kennzeichnung haben kann. |
| **Textstelle** | â€Also, mir ist das erst quasi zur Corona-Zeit richtig aufgefallen. Da wurde ja sehr, sehr viel Fehlinformation und Halbwahrheiten gestreut. Da habe ich auch entdeckt, dass das teilweise gekennzeichnet worden ist, dass das nicht komplett der Wahrheit entspricht. Sowohl als YouTube als auch Instagram, ich glaube auf TikTok sogar auch.â€œ (B5_01, Zeile 68-73) | â€Ich denke, es sollte schon immer prÃ¤sent sein, damit sich auch Falschnachrichten generell einfach weniger verbreiten. Gleichzeitig sollte es aber natÃ¼rlich nicht zu prÃ¤sent sein und nicht zu viel Platz in der Anwendung einnehmen.â€œ (B5_02, Zeile 113â€“116) <br> â€Vor allem in Situationen, wo man meinen kÃ¶nnte, dass die Information wirklich zutreffend ist, weil das fÃ¼r das eigene Bild in einem gewissen Themenbereich sehr wahrscheinlich klingt oder einleuchtend klingt, dass man das dann tendenziell sogar eher aufnehmen kann. KI's kÃ¶nnten da wirklich helfen, Nutzer aufmerksam zu machen, dass sich das da nicht um eine verifizierte Meinung handelt, sondern um irgendwelche erfundenen Sachen oder gezielten Fehlinformationen.â€œ (B5_01, Zeile 97â€“105) | â€Ja also ich finde das sollte ein gesondertes Team sein es gibt ja auch zum Beispiel ein Ethikrat wenn es um Thema KI geht, was KI machen darf und was nicht. Die wÃ¤ren zum Beispiel eine interessante Anlaufstelle dafÃ¼r, damit man halt so gut es geht EinflÃ¼sse von Dritten vermeiden kÃ¶nnte, die halt interne Ziele verfolgen.â€œ (B5_01, Zeile 197â€“202) <br> â€Andererseits wÃ¼rde ich auch eine kleine Gefahr darin sehen, wenn man als Mensch diese KI dafÃ¼r nutzt, um sich Informationen bestÃ¤tigen zu lassen oder den Wahrheitsgehalt herauszufinden. Wenn man sich dann fÃ¤lschlicherweise zu sehr auf die KI verlÃ¤sst und die KI aber doch mal einen Fehler macht, wie das aktuell auch schon vorkommt.â€œ (B5_02, Zeile 82â€“87) |

### Ergebnisse in Textform:

In diesem Abschnitt fassen wir die Ergebnisse unserer qualitativen Forschung zusammen. Wir fÃ¼hrten und analysierten zwei Interviews zum Thema â€KI als Werkzeug zur Erkennung von Fake Newsâ€œ. Beide Befragten haben bereits Erfahrung mit dem Umgang mit Social-Media, Fake-News und KI-Tools gemacht. Daher sind ihre Gedanken und Meinung sehr relevant fÃ¼r unsere Forschungsfrage, denn sie kÃ¶nnen uns direkt aus erster Hand berichten.

#### Vorwissen

ZunÃ¤chst erfuhren wir etwas Ã¼ber die Vorkenntnisse der Probanden. Dabei konnten wir feststellen, dass sie bereits Kontakt mit Fake-News hatten und einige Social Media-Plattformen sogar bereits versuchen dagegen vorzugehen (vgl. B5_01, Zeile 68 -73). Das bietet eine gute Grundlage fÃ¼r unseren Ansatz, den ganzen Vorgang durch ein KI-Tool zu automatisieren.

#### Implementierung

Danach ging es um die Implementierung. In diesem Abschnitt geht es darum, wie sich die Befragten die Implementierung des Tools vorstellen. Man sollte bei der Implementierung auf ein Gleichgewicht aus PrÃ¤gnanz und UnauffÃ¤lligkeit achten. Die KI soll helfen, aber nicht Ã¼berfordern. Wichtig ist auch den Benutzer auf fehlende Verifizierungen oder Quellen aufmerksam zu machen, besonders wenn der Inhalt auf den ersten Blick logisch erscheint.

#### Gefahren von KI-Tools

Auch die Gefahren der KI wurden in unseren Interviews angesprochen. Hierbei werden von unseren Probanden wichtige ethische Probleme angesprochen. Es geht darum, wer die KI kontrolliert und wie man dafÃ¼r sorgen kann, dass sie so gut es geht neutral bliebt. Daher wird z.B. ein Ethikrat vorgeschlagen, welcher dafÃ¼r sorgt, dass Dritte keinen Einfluss auf die KI haben kÃ¶nnen und Interessenkonflikte vermieden werden kÃ¶nnen. (vgl. B5_01, Zeile 197-202) Ein weiteres Problem ergibt sich, wenn die Benutzer sich zu sehr auf die KI verlassen. So kann es passieren, dass sie einen Fehler macht und Fake-News nicht als solche markiert werden. â€Wenn man sich dann fÃ¤lschlicherweise zu sehr auf die KI verlÃ¤sst und die KI aber doch mal einen Fehler macht, wie das aktuell auch schon vorkommt.â€œ(B5_02, Zeile 82-87). Auch dies muss man bei der Implementierung des KI-Tools beachten.

## Quantitativer Methodenteil

### Ablauf

FÃ¼r Ablauf entwickelten wir folgendes Diagramm:

```{mermaid}
flowchart TD 
n1["Start"] --> n2["DatenschutzerklÃ¤rung"] 
n2 --> n3["Pre-Test-Fragebogen"] 
n3 --> n4["Baseline: Klassifizierung von 10 Posts ohne KI"]
n4 --> n5["Post-Baseline-Fragebogen"] 
n5 --> n10["Randomisierung"] 
n10 --> n11["Evaluative KI"] 
n10 --> n12["Empfehlende KI"] 
n11 --> n16["Post-Test-Fragebogen"] 
n12 --> n16 
n16 --> n17["Verabschiedung und Dank"] 
n17 --> n18["VP-Stunden-Umfrage"]
```

Unsere Datenerhebung erfolgt im Rahmen einer Studie, welche Ã¼ber DSSLab online durchgefÃ¼hrt wird. Der geplante Zeitraum geht vom 31.05.2025 bis zum 09.06.2025 um 23:59 Uhr. Die Rekrutierung beginnt bereits kurz vor dem 31.05.2025. Die Studie startet mit der DatenschutzerklÃ¤rung und Informationen zum Ablauf(siehe Diagramm). AnschlieÃŸend beginnt der Fragen-Teil. Die Proband\*innen mÃ¼ssen zunÃ¤chst Fragen zum Vorwissen zu KÃ¼nstlicher Intelligenz (KI) beantworten. Danach beginnt der Hauptteil der Studie: Die Teilnehmenden sollen versuchen, in zwei verschiedenen Szenarien vorgegebene Social-Media-Posts zu bewerten, wÃ¤hrend sie gleichzeitig auf eine kleine, farbenwechselnde Grafik reagieren. Im ersten Szenario mÃ¼ssen die Probanden alleine entscheiden, ob die gezeigten Posts Desinformationen oder wahre Informationen enthalten (Schritt 4: "Baseline: Klassifizierung von 10 Posts ohne KI"). Dazu bekommen sie nach der Bewertung von 10 Posts einen Fragebogen zum gerade abgeschlossenen Versuch. Dabei sollen die Empfindungen und GefÃ¼hle der Personen festgehalten werden. Nun folgt ein Ã¤hnliches Szenario, nur dass diesmal eine KÃ¼nstliche Intelligenz bereitgestellt wird um die Proband\*innen beim Bewerten zu unterstÃ¼tzen. Hierbei wird zufÃ¤llig zwischen evaluativer und empfehlender KI ausgewÃ¤hlt.( siehe Diagramm) Auch danach werden die Empfindungen der Testpersonen gemessen. Zum Abschluss der Online-Studie gibt es eine Danksagung und Studierende der UniversitÃ¤t zu LÃ¼beck kÃ¶nnen VP-Stunden beantragen.

### Eigenschaften der Stichprobe

FÃ¼r diese Stichprobe nehmen wir uns vor, Menschen mit verschiedenen BildungsabschlÃ¼ssen und Altersgruppen zu rekrutieren. MinderjÃ¤hrige werden ausgeschlossen, aus GrÃ¼nden des Datenschutzes. AuÃŸerdem wird niemand aus unserer eigenen Gruppe oder Teilnehmende des Kurses â€Statistik und Methoden der Nutzerforschungâ€œ eingeschlossen, da wir Interessenskonflikte vermeiden mÃ¶chten. Insgesamt versuchen wir mindestens 18 Teilnehmer zu finden, da wir pro Mitglied jeweils mindestens 3 Personen brauchen. Dazu werden Studierende der UniversitÃ¤t zu LÃ¼beck, sowie Freunde und Familie rekrutiert.

### GewÃ¤hlte Erhebungsmethode

Zur Erhebung unserer Daten nutzten wir eine standardisierte Online-Umfrage, die Ã¼ber die Plattform DSSLab bereitgestellt wurde. Die Erhebung fand im Zeitraum vom 31.05.2025 bis zum 09.06.2025 um 23:59 Uhr statt. Die Teilnahme war freiwillig, anonymisiert und datenschutzkonform. Zielgruppe waren deutschsprachige Erwachsene Ã¼ber 18 Jahren mit Internetzugang.

#### GewÃ¤hlte Skalen

Die Online-Studie ist in mehrere FragenblÃ¶cke unterteilt und umfasste sowohl demografische Angaben als auch psychologische Konstrukte wie TechnikaffinitÃ¤t, Vertrauen in KI-generierte Inhalte und Vorwissen Ã¼ber KÃ¼nstliche Intelligenz. ZunÃ¤chst wurden demografische Daten erfasst.azu zÃ¤hlten das Alter (metrisch, Freitexteingabe), das Geschlecht (nominal, Auswahl: mÃ¤nnlich, weiblich, anderes mit Freitextoption), sowie der hÃ¶chste allgemeinbildende (ordinal, 5 Stufen) und berufliche Bildungsabschluss (ordinal, 6 Stufen). Dann folgt ein Block zu der Nutzung von sozialen Medien. Hier wurde die NutzungshÃ¤ufigkeit (ordinal, 5 Stufen-Skala von â€nieâ€œ bis â€tÃ¤glichâ€œ) sowie genutzte Plattformen (nominal, Mehrfachauswahl) und Hauptnutzungsmotive (ebenfalls nominal, Mehrfachauswahl) abgefragt. Diese Kategorien basierten auf aktuellen Social-Media-Statistiken nach RÃ¶hl (2024). FÃ¼r die Erfassung des Vorwissens zur KÃ¼nstlichen Intelligenz verwenden wir eine metrische 5-Punkt-Skala, von 1 = sehr wenig bis 5= sehr viel. AuÃŸerdem wird das Misstrauen gegenÃ¼ber von KI generierten Informationen auch mit einer metrischen Skala von 1 bis 5 gemessen. Mithilfe der Affinity for Technology Interaction Scale (ATI-Skala) nach Franke et al. (2019) wird die TechnikaffinitÃ¤t der Teilnehmer erfasst. Die Skala besteht aus 9 Items, die auf einer 6-Stufen metrischen Likert-Skala beantwortet wurden. ZusÃ¤tlich wurde ein Item zur Technikbereitschaft us der Kurzskala von Neyer et al. (2016) verwendet: â€Hinsichtlich technischer Neuentwicklungen bin ich sehr neugierigâ€œ, beantwortet auf einer 5-Stufen metrischen Skala (1 = stimmt gar nicht bis 5 = stimmt vÃ¶llig).

### Geplante Analysen

Wir planen mindestens einen t-Test und eine Korrelation, um Daten fÃ¼r unsere Forschungsfragen zu sammeln. Beim unserem t-Test kÃ¶nnen wir die beiden Szenarien miteinander vergleichen. Dabei ist die unabhÃ¤ngige Variable das genaue Szenario, bedeutet entweder mit oder ohne KI-UnterstÃ¼tzung. Die abhÃ¤ngige Variable ist die Bewertung, ob die Information stimmt. DafÃ¼r benutzen wir einen paired t-Test. Die Proband\*innen werden einmal nach dem Durchlauf ohne KI-UnterstÃ¼tzung und einmal nach dem Durchlauf mit KI-UnterstÃ¼tzung befragt. Ebenso kÃ¶nnte man untersuchen ob eine Gruppe mit hohem Vorwissen anders bewertet als eine Gruppe mit wenig Vorwissen. Die unabhÃ¤ngige Variable ist hier die Gruppe, in der sich die Proband*innen befinden*. Die abhÃ¤ngige Variable ist erneut die Bewertung. Dies wÃ¤re ein independent t-test. Des Weiteren untersuchen die Korrelation zwischen Vorkenntnissen und Ergebnissen, sowie zwischen Alter und den Ergebnissen. Dabei gehen wir davon aus, dass Personen mit hohen Vorkenntnissen Ã¶fter richtig liegen. Bei der zweiten Korrelation ist die Vermutung, dass jÃ¼ngere Teilnehmer\*innen die Desinformation besser erkennen. Bei der ersten Korrelation sind die Variablen: 1. Vorkenntnisse und 2. Bewertungen. Bei der zweiten Korrelation sind es 1. Alter und 2. Bewertungen.

# Diskussion

## *(Diskussion einfÃ¼gen)*

# AnhÃ¤nge

## Anhang 1 - Rekrutierungstext (Online)

**"Hilf uns Fake News zu bekÃ¤mpfen!**

Immer mehr Menschen werden durch Fake News im Internet beeinflusst. Um das zu verhindern, untersuchen wir in unserer Online-Studie wie man KÃ¼nstliche Intelligenz dazu nutzen kann, um Falschinformationen zu erkennen und Menschen davor zu warnen. DafÃ¼r brauchen wir jetzt deine Hilfe.

**ğŸ•’ Dauer:Â  ca. 1h**

ğŸ **VergÃ¼tung:** **1 VP-Stunde**

âœ… **Bedingungen:**

-   *min. 18 Jahre alt*

-   *nicht Teilnehmer\*in im Kurs "Statistik und Methoden der Nutzerforschung"*

-   *keine Teilnahme per Smartphone*

ğŸ”— **Teilnahmelink:**

[Link zur Studie](https://dsslab.hciuse.sh/study/pilot?groupId=gr-b5)

Wir freuen uns, wenn du uns unterstÃ¼tzt :)."

"Tommy05lol"

"DefoNotAlex"

"Matt1s1234"

"NeiUt"

"jakolex03"
